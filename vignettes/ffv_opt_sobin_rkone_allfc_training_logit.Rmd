---
title: BINARY--NSW Training EMPLOYMENT as Outcome Optimal Allocation Solution
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BINARY--NSW Training EMPLOYMENT as Outcome Optimal Allocation Solution}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
urlcolor: blue
---

Back to **[Fan](https://fanwangecon.github.io/)**'s Optimal Allocation Homepage **[Table of Content](https://fanwangecon.github.io/PrjOptiAlloc/)**

# Objective

Test binary allocation queue with Lalonde training dataset. There are 722 observations, 297 in the treatment group, 425 in the control group.

**Objective One**:

estimate a logit regression using the [Lalonde (1986)](https://fanwangecon.github.io/PrjOptiAlloc/reference/df_opt_lalonde_training.html) dataset. Include age, education, and race as controls.

**Generate and Analyze $A_i$ and $\alpha_i$**

1. Generate and show how to generate $A_i$ and $\alpha_i$ in the binary allocation Space
2. What is the correlation between $A$ and $\alpha$
3. What is the relationship between $x$ and $A$ and $\alpha$, when there is one x covariate, when there are multiple?

**Solve for Optimal Allocations**

Uses the binary allocation function as well as the planner iterator to solve for optimal binary targeting queue. These queue tell the planner, given the planner's preferences, who should optimally receive allocations.

## Set Up

```{r GlobalOptions, echo = T, results = 'hide', message=F, warning=F}
# dev.off(dev.list()["RStudioGD"])
rm(list = ls(all.names = TRUE))
options(knitr.duplicate.label = 'allow')
```
```{r loadlib, echo = T, results = 'hide', message=F, warning=F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(REconTools)

library(PrjOptiAlloc)
```

## Get Data

```{r data set up}
data(df_opt_lalonde_training)
# dft stands for dataframe training
dft <- df_opt_lalonde_training %>% mutate(id = X) %>%
           select(-X) %>%
           select(id, everything()) %>%
           mutate(emp78 =
                    case_when(re78 <= 0 ~ 0,
                              TRUE ~ 1)) %>%
           mutate(emp75 =
                    case_when(re75 <= 0 ~ 0,
                              TRUE ~ 1))

# Generate combine black + hispanic status
# 0 = white, 1 = black, 2 = hispanics
dft <- dft %>%
    mutate(race =
             case_when(black == 1 ~ 1,
                       hisp == 1 ~ 2,
                       TRUE ~ 0))

dft <- dft %>%
    mutate(age_m2 =
             case_when(age <= 23 ~ 1,
                       age >  23~ 2)) %>%
    mutate(age_m3 =
             case_when(age <= 20 ~ 1,
                       age > 20 & age <= 26 ~ 2,
                       age > 26 ~ 3))



dft$trt <- factor(dft$trt, levels = c(0,1), labels = c("ntran", "train"))

summary(dft)

# X-variables to use on RHS
ls_st_xs <- c('age', 'educ',
              'black','hisp','marr', 'nodeg')
svr_binary <- 'trt'
svr_binary_lb0 <- 'ntran'
svr_binary_lb1 <- 'train'
svr_outcome <- 'emp78'
sdt_name <- 'NSW Lalonde Training'
```

# Logit Regression

## Prediction with Observed Binary Input

Logit regression with a continuous variable and a binary variable. Predict outcome with observed continuous variable as well as observed binary input variable.

```{r logit with binary and continuous RHS, fig.height = 4, fig.width = 6, fig.align = "center"}
# Regress No bivariate
rs_logit <- glm(as.formula(paste(svr_outcome,
                                 "~", paste(ls_st_xs, collapse="+")))
                ,data = dft, family = "binomial")
summary(rs_logit)
dft$p_mpg <- predict(rs_logit, newdata = dft, type = "response")

# Regress with bivariate
# rs_logit_bi <- glm(as.formula(paste(svr_outcome,
#                                     "~ factor(", svr_binary,") + ",
#                                     paste(ls_st_xs, collapse="+")))
#                    , data = dft, family = "binomial")
rs_logit_bi <- glm(emp78 ~ 
                     age + I(age^2) + factor(age_m2)
                   + educ + I(educ^2) +
                   + educ + black + hisp + marr + nodeg
                   + factor(trt)
                   + factor(age_m2)*factor(trt)
                   , data = dft, family = "binomial")
summary(rs_logit_bi)

# Predcit Using Regresion Data
dft$p_mpg_hp <- predict(rs_logit_bi, newdata = dft, type = "response")

# Predicted Probabilities am on mgp with or without hp binary
scatter <- ggplot(dft, aes(x=p_mpg_hp, y=p_mpg)) +
      geom_point(size=1) +
      # geom_smooth(method=lm) + # Trend line
      geom_abline(intercept = 0, slope = 1) + # 45 degree line
      labs(title = paste0('Predicted Probabilities ', svr_outcome, ' on ', ls_st_xs, ' with or without hp binary'),
           x = paste0('prediction with ', ls_st_xs, ' and binary ', svr_binary, ' indicator, 1 is high'),
           y = paste0('prediction with only ', ls_st_xs),
           caption = paste0(sdt_name, ' simulated prediction')) +
      theme_bw()
print(scatter)
```

## Prediction with Binary set to 0 and 1

Now generate two predictions. One set where binary input is equal to 0, and another where the binary inputs are equal to 1. Ignore whether in data binary input is equal to 0 or 1. Use the same regression results as what was just derived.

Note that given the example here, the probability changes a lot when we

```{r logit prediction 0 vs 1, fig.height = 4, fig.width = 6, fig.align = "center"}
# Previous regression results
summary(rs_logit_bi)

# Two different dataframes, mutate the binary regressor
dft_bi0 <- dft %>% mutate(!!sym(svr_binary) := svr_binary_lb0)
dft_bi1 <- dft %>% mutate(!!sym(svr_binary) := svr_binary_lb1)

# Predcit Using Regresion Data
dft$p_mpg_hp_bi0 <- predict(rs_logit_bi, newdata = dft_bi0, type = "response")
dft$p_mpg_hp_bi1 <- predict(rs_logit_bi, newdata = dft_bi1, type = "response")

# Predicted Probabilities and Binary Input
scatter <- ggplot(dft, aes(x=p_mpg_hp_bi0)) +
      geom_point(aes(y=p_mpg_hp), size=4, shape=4, color="red") +
      geom_point(aes(y=p_mpg_hp_bi1), size=2, shape=8) +
      # geom_smooth(method=lm) + # Trend line
      geom_abline(intercept = 0, slope = 1) + # 45 degree line
      labs(title = paste0('Predicted Probabilities and Binary Input',
                          '\ncross(shape=4)/red is predict actual binary data',
                          '\nstar(shape=8)/black is predict set binary = 1 for all'),
           x = paste0('prediction with ', ls_st_xs, ' and binary ', svr_binary, ' = 0 for all'),
           y = paste0('prediction with ', ls_st_xs, ' and binary ', svr_binary, ' = 1'),
           caption = paste0(sdt_name, ' simulated prediction')) +
      theme_bw()
print(scatter)
```

# Generate and Analyze A and alpha

## Prediction with Binary set to 0 and 1 Difference

What is the difference in probability between binary = 0 vs binary = 1. How does that relate to the probability of outcome of interest when binary = 0 for all.

In the binary logit case, the relationship will be hump--shaped by construction between $A_i$ and $\alpha_i$. In the exponential wage cases, the relationship is convex upwards.

```{r logit prediction marginal vs base, fig.height = 4, fig.width = 7, fig.align = "center"}
# Generate Gap Variable
dft <- dft %>% mutate(alpha_i = p_mpg_hp_bi1 - p_mpg_hp_bi0) %>%
                mutate(A_i = p_mpg_hp_bi0)

dft_graph <- dft
dft_graph$age_m2 <- factor(dft_graph$age_m2, labels = c('Age <= 23', 'Age > 23'))

# Titling
title_line1 <- sprintf("Employment A_i and alpha_i (Logit), NSW Training Lalonda (AER, 1986)")
title_line2 <- sprintf("Individual Specific alpha_i from Nonlinearity")

# Binary Marginal Effects and Prediction without Binary
scatter <- dft_graph %>% ggplot(aes(x=A_i)) +
      geom_point(aes(y=alpha_i, color=factor(age_m2)), size=4, shape=4) +
      geom_abline(intercept = 0, slope = 1) + # 45 degree line
      scale_colour_manual(values=c("#69b3a2", "#404080")) +
      labs(title = paste0(title_line1, '\n', title_line2),
           x = 'A_i = Prob of Employment no Training)',
           y = 'alpha_i = P(train=1) - P(train=0)',
           caption = paste0('Logit Employment on training. Control for age, educ, race. Age <= 23 or > 23 interaction.'))
print(scatter)
```

## X variables and A and alpha

Given the x-variables included in the logit regression, how do they relate to A_i and alpha_i

```{r logit prediction marginal vs base along covariate x, fig.height = 4, fig.width = 6, fig.align = "center"}
# Generate Gap Variable
dft <- dft %>% mutate(alpha_i = p_mpg_hp_bi1 - p_mpg_hp_bi0) %>%
                mutate(A_i = p_mpg_hp_bi0)

# Binary Marginal Effects and Prediction without Binary
ggplot.A.alpha.x <- function(svr_x, df,
                             svr_alpha = 'alpha_i', svr_A = "A_i"){

  scatter <- ggplot(df, aes(x=!!sym(svr_x))) +
        geom_point(aes(y=alpha_i), size=4, shape=4, color="red") +
        geom_point(aes(y=A_i), size=2, shape=8, color="blue") +
        geom_abline(intercept = 0, slope = 1) + # 45 degree line
        labs(title = paste0('A (blue) and alpha (red) vs x variables=', svr_x),
             x = svr_x,
             y = 'Probabilities',
             caption = paste0(sdt_name, ' simulated prediction')) +
        theme_bw()

return(scatter)
}

# Plot over multiple
lapply(ls_st_xs,
       ggplot.A.alpha.x,
       df = dft)
```

# Optimal Binary Allocation

## Solve for Optimal Allocaions Across Preference Parameters

Invoke the binary optimal allocation function *ffp_opt_anlyz_rhgin_bin* that loops over rhos.

```{r}
beta_i <- rep(1/dim(dft)[1], times=dim(dft)[1])
dft <- cbind(dft, beta_i)
ar_rho = c(-100, -0.001,  0.95)
ar_rho <- 1 - (10^(c(seq(-2,2, length.out=30))))
ar_rho <- unique(ar_rho)

ls_bin_solu_all_rhos <-
  ffp_opt_anlyz_rhgin_bin(dft, svr_id_i = 'id',
                          svr_A_i = 'A_i', svr_alpha_i = 'alpha_i', svr_beta_i = 'beta_i',
                          ar_rho = ar_rho,
                          svr_inpalc = 'opti_alloc_queue',
                          svr_expout = 'opti_exp_outcome')

df_all_rho <- ls_bin_solu_all_rhos$df_all_rho
df_all_rho_long <- ls_bin_solu_all_rhos$df_all_rho_long

# How many people have different ranks across rhos
it_how_many_vary_rank <- sum(df_all_rho$rank_max - df_all_rho$rank_min)
it_how_many_vary_rank
```

## Change in Rank along Lambda

```{r graph of rank change, fig.height = 4, fig.width = 7, fig.align = "center"}

# generate dataframe of lambda
mt_combine <- cbind(ar_rho)
colnames(mt_combine) <- c('lambda')

# get rank when wage rho = 1
df_all_rho_rho_c1 <- df_all_rho %>% select(id, rho_c1_rk)

# rho really means rho index
tb_lambda <- as_tibble(mt_combine) %>% rowid_to_column(var = "rho")

# Merge 
df_all_rho_long <- df_all_rho_long %>% mutate(rho = as.numeric(rho)) %>% 
                      left_join(tb_lambda, by='rho') %>%
                      left_join(df_all_rho_rho_c1, by='id')

# Select subset to graph
df_rank_graph <- df_all_rho_long %>% 
                    mutate(id = factor(id)) %>%
                    filter((id == 2221) |  # utilitarian rank = 1
                           (id == 58) |  # utilitarian rank = 101
                           (id == 710)  |  # utilitarian rank = 201
                           (id == 57) |  # utilitarian rank = 301
                           (id == 74)|  # utilitarian rank = 401
                           (id == 248) |  # utilitarian rank = 501
                           (id == 206) |  # utilitarian rank = 601
                           (id == 272)   # utilitarian rank = 701
                             ) %>% 
                    mutate(one_minus_lambda = 1 - lambda) %>% 
                    mutate(rho_c1_rk = factor(rho_c1_rk)) 

df_rank_graph$rho_c1_rk

df_rank_graph$id <- factor(df_rank_graph$rho_c1_rk,
                           labels = c('Rank= 1 when λ=0.99', #200
                                      'Rank= 101 when λ=0.99', #110
                                      'Rank= 201 when λ=0.99', #95
                                      'Rank= 301 when λ=0.99', #217
                                      'Rank= 401 when λ=0.99', #274
                                      'Rank= 501 when λ=0.99', #101
                                      'Rank= 601 when λ=0.99', #131
                                      'Rank= 701 when λ=0.99' #3610
                                       ))

# x-labels
x.labels <- c('λ=0.99', 'λ=0.90', 'λ=0', 'λ=-10', 'λ=-100')
x.breaks <- c(0.01, 0.10, 1, 10, 100)

# title line 2
title_line1 <- sprintf("EMPLOY LOGIT: Optimal Tageting Queue, NSW Lalonda (AER, 1986)")
title_line2 <- sprintf("How Do Allocation Rankings (Targeting Queue) Shift with λ?")

# Graph Results--Draw
line.plot <- df_rank_graph %>% 
  ggplot(aes(x=one_minus_lambda, y=rank,
             group=fct_rev(id), 
             colour=fct_rev(id), size=2)) + 
  # geom_line(aes(linetype =fct_rev(id)), size=0.75) +
  geom_line(size=0.75) +
  geom_vline(xintercept=c(1), linetype="dotted") +
  labs(title = paste0(title_line1, '\n', title_line2),
       x = 'log10 Rescale of λ, Log10(λ)\nλ=1 Utilitarian, λ=-infty Rawlsian',
       y = 'Optimal Targeting Queue Rank (1=highest)',
       caption = 'Training RCT with 297 treated, 425 untreated. Optimal Binary Targeting Queue.') +
  scale_x_continuous(trans='log10', labels = x.labels, breaks = x.breaks) +
  theme_bw()

print(line.plot)


```

## Save Results

```{r saving file}

# Change Variable names so that this can becombined with logit file later
df_all_rho <- df_all_rho %>% rename_at(vars(starts_with("rho_")), funs(str_replace(., "rk", "rk_employ")))
df_all_rho <- df_all_rho %>% 
        rename(A_i_employ = A_i, alpha_i_employ = alpha_i, beta_i_employ = beta_i,
               rank_min_employ = rank_min, rank_max_employ = rank_max, avg_rank_employ = avg_rank)

# Save File
df_opt_lalonde_training_employ <- df_all_rho
usethis::use_data(df_opt_lalonde_training_employ, df_opt_lalonde_training_employ, overwrite = TRUE)
```

## Binary Marginal Effects and Prediction without Binary

What is the relationship between ranking,

```{r}
# ggplot.A.alpha.x <- function(svr_x, df,
#                              svr_alpha = 'alpha_i', svr_A = "A_i"){
#
#   scatter <- ggplot(df, aes(x=!!sym(svr_x))) +
#         geom_point(aes(y=alpha_i), size=4, shape=4, color="red") +
#         geom_point(aes(y=A_i), size=2, shape=8, color="blue") +
#         geom_abline(intercept = 0, slope = 1) + # 45 degree line
#         labs(title = paste0('A (blue) and alpha (red) vs x variables=', svr_x),
#              x = svr_x,
#              y = 'Probabilities',
#              caption = paste0(sdt_name, ' simulated prediction')) +
#         theme_bw()
#
# return(scatter)
# }
```
